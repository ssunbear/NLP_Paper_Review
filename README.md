# NLP Paper Review

NLP와 관련된 논문을 읽고 정리한 레포입니다. 

## 구성 
|**Category**|**Paper**|**Date**|**Link**|
| ------------------------ | ------------| ----------- |----------- |
|`Seq2seq`|[**Sequence to Sequence Learning with Neural Networks**]|`2024.08.30`|[링크](https://arxiv.org/abs/1409.3215)|
|`Transformer`|[**Attention is All You Need**]|`2024.09.13`|[링크](https://arxiv.org/abs/1706.03762)|
|`PLM-Encoder` `ELMo`|[**Deep contextualized word representations**]|`2024.09.13`|[링크](https://arxiv.org/abs/1802.05365)|
|`PLM-Encoder` `BERT`|[**BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding**]|`2024.09.27`|[링크](https://arxiv.org/abs/1409.3215)|
|`PLM-Decoder` `GPT-2`|[**Language Models are Unsupervised Multitask Learners**]|`2024.09.27`|[링크](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)|
|`PLM-seq2seq` `T5`|[**Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer**]|`2024.10`|[링크](https://arxiv.org/abs/1910.10683)|
|`PLM-Decoder` `InstructGPT`|[**Training language models to follow instructions with human feedback**]|`2024.10`|[링크](https://arxiv.org/abs/2203.02155)|
|`PLM-Decoder` `LLaMA`|[**LLaMA: Open and Efficient Foundation Language Models**]|`2024.10`|[링크](https://arxiv.org/abs/2302.13971)|
|`Alignment Tuning` `DPO`|[**Direct Preference Optimization: Your Language Model is Secretly a Reward Model**]|`2024.10`|[링크](https://arxiv.org/abs/2305.18290)|
|`Instruction Tuning` `LIMA`|[**LIMA: Less Is More for Alignment**]|`2024.10`|[링크](https://arxiv.org/abs/2305.11206)|
|`PEFT` `LoRA`|[**LoRA: Low-Rank Adaptation of Large Language Models**]|`2024.10`|[링크](https://arxiv.org/abs/2302.13971)|
|`Scaling Law`|[**Scaling Laws for Neural Language Models**]|`2024.10`|[링크](https://arxiv.org/abs/2001.08361)|
|`Scaling Law` `Chinchilla`|[**Training Compute-Optimal Large Language Models**]|`2024.10`|[링크](https://arxiv.org/abs/2203.15556)|
